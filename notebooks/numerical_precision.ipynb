{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f8137ba-c6b2-48e8-81a3-0414c5b75a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0de9522f-9f3a-4613-aaad-49a2de1369d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da3b681c-7b94-4aed-a591-c6deca1dd3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import triton\n",
    "import triton.language as tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dfbbfcd-0a6d-4a23-b695-e34ba40cbde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from triton.language.extra.cuda.libdevice import tanh, sqrt, erf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9449675-0a83-4263-980b-4054f3aa9fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dda4357d-f18a-426f-8a00-dcb5116b6c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6469f905-bb1b-4506-a810-becdc6e3f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def gelu_approx(x):\n",
    "    \"\"\"\n",
    "    GeLU_ activation - Gaussian error linear unit, with tanh approximation\n",
    "\n",
    "    .. _GeLU: https://arxiv.org/pdf/1606.08415.pdf\n",
    "    \"\"\"\n",
    "    return 0.5 * x * (1.0 + tanh(0.79788456760809 * x * (1.0 + 0.044715 * x * x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19ee61ab-2a4b-412d-b451-969b5a5ec357",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def gelu_approx(x):\n",
    "    \"\"\"\n",
    "    GeLU_ activation - Gaussian error linear unit, with tanh approximation\n",
    "\n",
    "    .. _GeLU: https://arxiv.org/pdf/1606.08415.pdf\n",
    "    \"\"\"\n",
    "    return 0.5 * x * (1.0 + tanh(0.7978845608028654 * x * (1.0 + 0.044715 * x * x)))\n",
    "\n",
    "\n",
    "@triton.jit\n",
    "def gelu_approx_grad(x):\n",
    "    # CREDITS: Fast implementation proposed in\n",
    "    # https://github.com/NVIDIA/Megatron-LM/blob/main/megatron/model/fused_bias_gelu.py#L30\n",
    "    tanh_out = tanh(0.79788456 * x * (1 + 0.044715 * x * x))\n",
    "    return 0.5 * x * (\n",
    "        (1 - tanh_out * tanh_out) * (0.79788456 + 0.1070322243 * x * x)\n",
    "    ) + 0.5 * (1 + tanh_out)\n",
    "\n",
    "\n",
    "@triton.autotune(\n",
    "    configs=[\n",
    "        triton.Config(\n",
    "            {\"BLOCK_M\": 128, \"BLOCK_N\": 256, \"BLOCK_K\": 32, \"SPLIT_K\": 1},\n",
    "            num_stages=3,\n",
    "            num_warps=8,\n",
    "        ),\n",
    "        triton.Config(\n",
    "            {\"BLOCK_M\": 256, \"BLOCK_N\": 128, \"BLOCK_K\": 32, \"SPLIT_K\": 1},\n",
    "            num_stages=3,\n",
    "            num_warps=8,\n",
    "        ),\n",
    "        triton.Config(\n",
    "            {\"BLOCK_M\": 256, \"BLOCK_N\": 64, \"BLOCK_K\": 32, \"SPLIT_K\": 1},\n",
    "            num_stages=4,\n",
    "            num_warps=4,\n",
    "        ),\n",
    "        triton.Config(\n",
    "            {\"BLOCK_M\": 64, \"BLOCK_N\": 256, \"BLOCK_K\": 32, \"SPLIT_K\": 1},\n",
    "            num_stages=4,\n",
    "            num_warps=4,\n",
    "        ),\n",
    "        triton.Config(\n",
    "            {\"BLOCK_M\": 128, \"BLOCK_N\": 128, \"BLOCK_K\": 32, \"SPLIT_K\": 1},\n",
    "            num_stages=4,\n",
    "            num_warps=4,\n",
    "        ),\n",
    "        triton.Config(\n",
    "            {\"BLOCK_M\": 128, \"BLOCK_N\": 64, \"BLOCK_K\": 32, \"SPLIT_K\": 1},\n",
    "            num_stages=4,\n",
    "            num_warps=4,\n",
    "        ),\n",
    "        triton.Config(\n",
    "            {\"BLOCK_M\": 64, \"BLOCK_N\": 128, \"BLOCK_K\": 32, \"SPLIT_K\": 1},\n",
    "            num_stages=4,\n",
    "            num_warps=4,\n",
    "        ),\n",
    "        triton.Config(\n",
    "            {\"BLOCK_M\": 128, \"BLOCK_N\": 32, \"BLOCK_K\": 32, \"SPLIT_K\": 1},\n",
    "            num_stages=4,\n",
    "            num_warps=4,\n",
    "        ),\n",
    "        triton.Config(\n",
    "            {\"BLOCK_M\": 64, \"BLOCK_N\": 32, \"BLOCK_K\": 32, \"SPLIT_K\": 1},\n",
    "            num_stages=5,\n",
    "            num_warps=2,\n",
    "        ),\n",
    "        # good for int8\n",
    "        triton.Config(\n",
    "            {\"BLOCK_M\": 128, \"BLOCK_N\": 256, \"BLOCK_K\": 128, \"SPLIT_K\": 1},\n",
    "            num_stages=3,\n",
    "            num_warps=8,\n",
    "        ),\n",
    "        triton.Config(\n",
    "            {\"BLOCK_M\": 256, \"BLOCK_N\": 128, \"BLOCK_K\": 128, \"SPLIT_K\": 1},\n",
    "            num_stages=3,\n",
    "            num_warps=8,\n",
    "        ),\n",
    "        triton.Config(\n",
    "            {\"BLOCK_M\": 256, \"BLOCK_N\": 64, \"BLOCK_K\": 128, \"SPLIT_K\": 1},\n",
    "            num_stages=4,\n",
    "            num_warps=4,\n",
    "        ),\n",
    "        triton.Config(\n",
    "            {\"BLOCK_M\": 64, \"BLOCK_N\": 256, \"BLOCK_K\": 128, \"SPLIT_K\": 1},\n",
    "            num_stages=4,\n",
    "            num_warps=4,\n",
    "        ),\n",
    "        triton.Config(\n",
    "            {\"BLOCK_M\": 128, \"BLOCK_N\": 128, \"BLOCK_K\": 128, \"SPLIT_K\": 1},\n",
    "            num_stages=4,\n",
    "            num_warps=4,\n",
    "        ),\n",
    "        triton.Config(\n",
    "            {\"BLOCK_M\": 128, \"BLOCK_N\": 64, \"BLOCK_K\": 64, \"SPLIT_K\": 1},\n",
    "            num_stages=4,\n",
    "            num_warps=4,\n",
    "        ),\n",
    "        triton.Config(\n",
    "            {\"BLOCK_M\": 64, \"BLOCK_N\": 128, \"BLOCK_K\": 64, \"SPLIT_K\": 1},\n",
    "            num_stages=4,\n",
    "            num_warps=4,\n",
    "        ),\n",
    "        triton.Config(\n",
    "            {\"BLOCK_M\": 128, \"BLOCK_N\": 32, \"BLOCK_K\": 64, \"SPLIT_K\": 1},\n",
    "            num_stages=4,\n",
    "            num_warps=4,\n",
    "        ),\n",
    "        triton.Config(\n",
    "            {\"BLOCK_M\": 64, \"BLOCK_N\": 32, \"BLOCK_K\": 64, \"SPLIT_K\": 1},\n",
    "            num_stages=5,\n",
    "            num_warps=2,\n",
    "        ),\n",
    "    ],\n",
    "    key=[\"CACHE_KEY_M\", \"CACHE_KEY_N\", \"CACHE_KEY_K\"],\n",
    ")\n",
    "@triton.heuristics(\n",
    "    {\n",
    "        \"EVEN_K\": lambda args: args[\"K\"] % (args[\"BLOCK_K\"] * args[\"SPLIT_K\"]) == 0,\n",
    "    }\n",
    ")\n",
    "@triton.jit\n",
    "def kernel_linear_gelu_fwd(\n",
    "    C,  # Pointers to matrices\n",
    "    ACT_INPUT,\n",
    "    A,\n",
    "    B,\n",
    "    bias,\n",
    "    # Matrix dimensions\n",
    "    M,\n",
    "    N,\n",
    "    K,\n",
    "    CACHE_KEY_M,\n",
    "    CACHE_KEY_N,\n",
    "    CACHE_KEY_K,\n",
    "    # The stride variables represent how much to increase the ptr by when moving by 1\n",
    "    # element in a particular dimension. E.g. stride_am is how much to increase a_ptr\n",
    "    # by to get the element one row down (A has M rows)\n",
    "    stride_cm,\n",
    "    # stride_cn,  # Assume that stride_cn == 1\n",
    "    stride_am,\n",
    "    stride_ak,\n",
    "    stride_bn,\n",
    "    stride_bk,\n",
    "    # Meta-parameters\n",
    "    BLOCK_M: tl.constexpr,\n",
    "    GROUP_M: tl.constexpr,\n",
    "    BLOCK_N: tl.constexpr,\n",
    "    BLOCK_K: tl.constexpr,\n",
    "    # split k not used, not performant with activation, kept because early_config_prune is expecting it\n",
    "    SPLIT_K: tl.constexpr,\n",
    "    EVEN_K: tl.constexpr,\n",
    "    A_ROWMAJOR: tl.constexpr,\n",
    "    B_COLMAJOR: tl.constexpr,\n",
    "    SAVE_ACT_INPUT: tl.constexpr,\n",
    "):\n",
    "    pid = tl.program_id(axis=0)\n",
    "\n",
    "    grid_m = (M + BLOCK_M - 1) // BLOCK_M\n",
    "    grid_n = (N + BLOCK_N - 1) // BLOCK_N\n",
    "    # re-order program ID for better L2 performance\n",
    "    width = GROUP_M * grid_n\n",
    "    group_id = pid // width\n",
    "    group_size = min(grid_m - group_id * GROUP_M, GROUP_M)\n",
    "    pid_m = group_id * GROUP_M + (pid % group_size)\n",
    "    pid_n = (pid % width) // (group_size)\n",
    "\n",
    "    # now compute the block that each program will go through\n",
    "    # rm (resp. rn) denotes a range of indices\n",
    "    # for rows (resp. col) of C\n",
    "    rm = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)\n",
    "    rn = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)\n",
    "    # trick to avoid masking on M and N axis\n",
    "    ram = tl.max_contiguous(tl.multiple_of(rm % M, BLOCK_M), BLOCK_M)\n",
    "    rbn = tl.max_contiguous(tl.multiple_of(rn % N, BLOCK_N), BLOCK_N)\n",
    "    rk = tl.arange(0, BLOCK_K)\n",
    "\n",
    "    if A_ROWMAJOR:\n",
    "        A = A + (ram[:, None] * stride_am + rk[None, :])\n",
    "    else:\n",
    "        A = A + (ram[:, None] * stride_am + rk[None, :] * stride_ak)\n",
    "    if B_COLMAJOR:\n",
    "        B = B + (rk[:, None] + rbn[None, :] * stride_bn)\n",
    "    else:\n",
    "        B = B + (rk[:, None] * stride_bk + rbn[None, :] * stride_bn)\n",
    "\n",
    "    acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)\n",
    "\n",
    "    for k in range(K, 0, -BLOCK_K):\n",
    "        if EVEN_K:\n",
    "            a = tl.load(A)\n",
    "            b = tl.load(B)\n",
    "        else:\n",
    "            a = tl.load(A, mask=rk[None, :] < k, other=0.0)\n",
    "            b = tl.load(B, mask=rk[:, None] < k, other=0.0)\n",
    "        acc += tl.dot(a, b)\n",
    "\n",
    "        if A_ROWMAJOR:\n",
    "            A += BLOCK_K\n",
    "        else:\n",
    "            A += BLOCK_K * stride_ak\n",
    "        if B_COLMAJOR:\n",
    "            B += BLOCK_K\n",
    "        else:\n",
    "            B += BLOCK_K * stride_bk\n",
    "\n",
    "    bias = tl.load(bias + rn, mask=rn < N, other=0.0).to(tl.float32)\n",
    "    acc += bias[None, :]\n",
    "\n",
    "    if SAVE_ACT_INPUT:\n",
    "        act_in_ptrs = ACT_INPUT + ram[:, None] * stride_cm + rbn[None, :]\n",
    "        tl.store(act_in_ptrs, acc)\n",
    "\n",
    "    acc = gelu_approx(acc)\n",
    "    rm = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)\n",
    "    rn = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)\n",
    "\n",
    "    C = C + rm[:, None] * stride_cm + rn[None, :]\n",
    "    mask = (rm < M)[:, None] & (rn < N)[None, :]\n",
    "    tl.store(C, acc)\n",
    "\n",
    "\n",
    "def triton_linear_gelu(\n",
    "    x: torch.Tensor,\n",
    "    weight: torch.Tensor,\n",
    "    bias: torch.Tensor,\n",
    "    save_act_input: bool = False,\n",
    ") -> torch.Tensor:\n",
    "    batch_shape, n = x.shape[:-1], x.shape[-1]\n",
    "    batch_dim = batch_shape.numel()\n",
    "    x_reshaped = x.reshape(batch_dim, n)\n",
    "\n",
    "    if x_reshaped.stride(0) > 1 and x_reshaped.stride(1) > 1:\n",
    "        x_reshaped = x_reshaped.contiguous()\n",
    "    if weight.stride(0) > 1 and weight.stride(1) > 1:\n",
    "        weight = weight.contiguous()\n",
    "    bias = bias.contiguous() if bias is not None else None\n",
    "\n",
    "    assert x.dtype == weight.dtype, (\n",
    "        f\"Input and weight must have the same dtype, got {x.dtype} and {weight.dtype}\"\n",
    "    )\n",
    "    if bias is not None:\n",
    "        assert x.dtype == bias.dtype, (\n",
    "            f\"Input and bias must have the same dtype, got {x.dtype} and {bias.dtype}\"\n",
    "        )\n",
    "    assert x_reshaped.shape[1] == weight.shape[1], (\n",
    "        f\"Incompatible dimensions: {x_reshaped.shape} - {weight.shape}\"\n",
    "    )\n",
    "\n",
    "    assert bias is None or bias.shape[0] == weight.shape[0], (\n",
    "        \"Incompatible dimensions in between weight and bias\"\n",
    "    )\n",
    "\n",
    "    M, K = x_reshaped.shape\n",
    "    N, K = weight.shape\n",
    "\n",
    "    output = torch.empty((M, N), device=x.device, dtype=x.dtype)\n",
    "    act_input = torch.empty_like(output) if save_act_input else None\n",
    "\n",
    "    grid = lambda META: (\n",
    "        triton.cdiv(M, META[\"BLOCK_M\"]) * triton.cdiv(N, META[\"BLOCK_N\"]),\n",
    "    )  # noqa\n",
    "\n",
    "    kernel_linear_gelu_fwd[grid](\n",
    "        output,\n",
    "        act_input,\n",
    "        x_reshaped,\n",
    "        weight,  # data ptrs\n",
    "        bias if bias is not None else x,  # auto skip bias if not present\n",
    "        M,  # shapes\n",
    "        N,\n",
    "        K,\n",
    "        M // 32,  # key for triton cache (limit number of compilations)\n",
    "        N // 32,\n",
    "        K // 32,\n",
    "        stride_cm=output.stride(0),  # strides\n",
    "        # stride_cn=output.stride(1),\n",
    "        stride_am=x_reshaped.stride(0),\n",
    "        stride_ak=x_reshaped.stride(1),\n",
    "        stride_bk=weight.stride(1),\n",
    "        stride_bn=weight.stride(0),\n",
    "        SAVE_ACT_INPUT=save_act_input,\n",
    "        A_ROWMAJOR=x_reshaped.stride(1) == 1,\n",
    "        B_COLMAJOR=weight.stride(1) == 1,\n",
    "        GROUP_M=8,  # speed optimization: group the programs\n",
    "    )\n",
    "\n",
    "    if not save_act_input:\n",
    "        return output.reshape(*batch_shape, output.shape[-1])\n",
    "    else:\n",
    "        return (\n",
    "            output.reshape(*batch_shape, output.shape[-1]),\n",
    "            act_input.reshape(*batch_shape, act_input.shape[-1]),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "945e918f-d1d2-4078-a005-fa7a0362546d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gelu_tanh(z: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    z: Tensor of any shape\n",
    "    returns: 0.5 * z * [1 + tanh(√(2/π)*(z + 0.044715*z^3))]\n",
    "    \"\"\"\n",
    "    coeff = math.sqrt(2.0 / math.pi)\n",
    "    return 0.5 * z * (1.0 + torch.tanh(coeff * (z + 0.044715 * z.pow(3))))\n",
    "\n",
    "def gelu_linear(X: torch.Tensor, W: torch.Tensor, b: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    X: (batch, in_features)\n",
    "    W: (out_features, in_features)\n",
    "    b: (out_features,)\n",
    "    All on CPU. By default does float32 → cast if you want float64.\n",
    "    \"\"\"\n",
    "    Z = F.linear(X, W, b)        # equivalent to X @ W.T + b\n",
    "    return gelu_tanh(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5afece4-ce4d-4174-95cb-c5e981b1faf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "dtype = torch.bfloat16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3de9cf3b-1dca-4127-b37a-e7b0604e2daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((1024, 1024), device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d577d07d-957c-48bc-9252-bb6de3716f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.randn((1024, 1024), device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ebb64a6-e59b-4d34-adf8-7a1361f3614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.randn((1024,), device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99c9c3a8-5d4a-47a6-8a51-cacf23b483a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cpu = x.to(device='cpu', dtype=torch.float32)\n",
    "W_cpu = W.to(device='cpu', dtype=torch.float32)\n",
    "b_cpu = b.to(device='cpu', dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b59a8272-6af9-48f0-b323-717d683ac432",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_normal = F.gelu(F.linear(x, W, b), approximate=\"tanh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b63a2d0-1314-4221-9aab-f172a57f128c",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_triton = triton_linear_gelu(x, W, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4854091-e239-4c86-a8ee-15d9ed91af3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_cpu = gelu_linear(x_cpu, W_cpu, b_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "172f6849-eb32-482e-96f5-9088ab395d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0180812384933233)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(out_cpu - out_normal.to(device='cpu', dtype=torch.float32)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aff15a58-efeb-467b-a532-504a92b44d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0180397387593985)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(out_cpu - out_triton.to(device='cpu', dtype=torch.float32)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2c27347-7da4-46f5-8861-742e7cfff0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_gpu = F.gelu(F.linear(x.to(dtype=torch.float32), W.to(dtype=torch.float32), b.to(dtype=torch.float32)), approximate=\"tanh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1faa81f8-3c6d-4bc9-a083-dc02a41a857f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0180812347680330, device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(out_gpu - out_normal.to(dtype=torch.float32)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9ab3737-4430-48da-a6f1-a7e07b70cc48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0180397368967533, device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(out_gpu - out_triton.to(dtype=torch.float32)).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
